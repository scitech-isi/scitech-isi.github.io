---
title: "Scitech at Supercomputing21"
image: /images/news/sc21_logo.png
description: "The SciTech group presents their latest work at SC21."
date: 2021-12-06
layout: post
categories:
  - news
---

<img align="right" width="300" height="300" src="/images/news/works-logo.png">

Members of the SciTech group have recently presented their latest research
in the WORKS Workshop at Supercomputing 21 in St. Louis Missouri. Presentations
covered a range of topics including GPU monitoring, machine learning workflows,
and science gateways. You can read more about these research efforts below.

## A Lightweight GPU Monitoring Extension for Pegasus Kickstart

**Authors**. George Papadimitriou (USC ISI), Ewa Deelman (USC ISI)

**Description**. This presentation presents a lightweight tool to capture 
monitoring information from Nvidia GPUs. The tool is an extension of the 
[Pegasus Kickstart](https://pegasus.isi.edu/documentation/manpages/pegasus-kickstart.html) 
wrapper designed for monitoring CPU-based workflow jobs.

## A Performance Characterization of Scientific Machine Learning Workflows

**Authors**. Patrycja Krawczuk (USC ISI), George Papadimitriou (USC ISI), Ryan
Tanaka (USC ISI), Tu Mai Anh Do (USC ISI), Srujana Subramanya (USC ISI), Shubham
Nagarkar (USC ISI), Aditi Jain (USC ISI), Kelsie Lam (USC ISI), Anirban Mandal
(RENCI), Loic Pottier (USC ISI), Ewa Deelman (USC ISI)

**Description**. Scientific workflows are one of the well-established pillars 
of modern large-scale computational science. More recently, scientists have 
started to leverage machine learning (ML) capabilities in their workflows, 
leading to a new category of scientific workflows, denoted as scientific ML 
workflows. ML is not only about training and inference, modern ML workflows 
also involve complex data processing steps before the training can start, which 
are not often accounted for in most performance studies. In this work, we 
consider scientific ML workflows, from data pre-processing to training, 
inference, and model evaluation. We aim to explore (i) how scientific ML 
workflows differ from more traditional scientific workflows and; (ii) how we 
can characterize ML workflows both in terms of execution time and data movements 
when executing on an exemplary cloud platform. We select three representative 
workflows, ranging from image classification to natural language processing and 
image segmentation, which have been executed using the academic cloud platform, 
Chameleon. We build four realistic deployment scenarios for each workflow, 
which stress data movements during workflow executions. Then, we compare the 
performance observed when utilizing these different configurations and study how 
different settings impact overall workflows performance and efficiency when 
running on cloud infrastructures. Finally, we summarize our findings and discuss 
performance impacts when augmenting scientific workflows with ML techniques and 
how traditional workflow management systems can improve their support for such 
workflows.

## VisDict: Enhancing the Communication between Workflow Providers and User Communities via a Visual Dictionary

**Authors**. Sandra Gesing (Discovery Partner Institute, University of Illinois Chicago),
Rafael Ferreira da Silva (USC ISI), Ewa Deelman (USC ISI), Michael Hildreth (University
of Notre Dame), Mary Ann McDowell (University of Notre Dame), Natalie Meyers (University
of Notre Dame), Ian Taylor (University of Notre Dame), Douglas Thain (University of
Notre Dame)

**Description**. Workflows have proved to be an excellent medium for representing 
scientific methods and for enhancing the efficiency and reproducibility of 
computational tasks. There is a strong need for close collaboration and intensive 
communication with domain scientists to successfully translate high-impact 
scientific methods into workflows. While there is a trend to make workflow 
editors and workflow dashboards as intuitive as possible, there is a lack of 
tools that support direct communication between scientists and workflow providers. 
The envisioned VisDict science gateway addresses this gap by providing a visual 
dictionary, translating terms, jargon, and concepts between research domains 
and workflow providers. The goal is to avoid misunderstandings, i.e. resulting 
from using the same word in different meanings such as the term ’experiment‘.
